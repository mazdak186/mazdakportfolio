---
title: "Machine Learning AI for Recognizing Handwritten Digits from Pictures"
date: 2020-04-15T15:34:30-04:00
categories:
  - School Project
tags:
  - Machine Learning
  - Python
toc: true
toc_label:
toc_icon: 'bars'
classes: wide
header:
  overlay_color: "#000"
  overlay_filter: "0.8"
  overlay_image: /assets/images/mnist_pic.png
  caption: 
excerpt: "Created a model from scratch using the popular MNIST database and the machine learning API: Tensorflow"
---

# Overview

The MNIST dataset is a set of handwritten digits that is commonly used as a benchmark for machine learning techniques. It is especially useful for building neural networks while spending minimal time preprocessing the images. The images are all centered with a fixed size of 28 by 28 pixels. This article will go through the steps necessary to build and train a neural network to identify handwritten digits outside of the given dataset. 

# Import Libraries

The Keras API is a user-friendly framework built on top of the Tensorflow platform. It is used to quickly develop deep-learning models by layering various building blocks. Numpy is a python library that will be used to handle the data we train the model with. And the four visualization libraries will help with understanding how the data is being manipulated.

```python
# import numpy for arrays
import numpy as np

# import keras libraries
import keras
from keras.models import load_model
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.optimizers import RMSprop
from keras.callbacks import EarlyStopping

# import visualization libraries
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from PIL import Image
```
  
# Loading the MNIST Dataset

The MNIST dataset must first be loaded into a training and testing dataset. There is a method we can call that will easily split the data into four different arrays. *train_data* is an array with a shape of (60000, 28, 28). This means it contains 60000 images with a 28 by 28 array of integers ranging from 0 to 255 where 0 is a pure black pixel and 255 is a pure white pixel. We can print the raw data of the first image in the training dataset below. 

```python
# import the data, split between train and test sets
(train_data, train_label), (test_data, test_label) = mnist.load_data()

# print the first datum
print(train_data[0])
```

**Output:**

    [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]
     [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]
     [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]
     [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
     [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]
     
<br/>

The pyplot library can help visualize the set of integers shown above as an actual image of the handwritten digit.

```python
print("First X in the training data:")
plt.imshow(train_data[0], cmap='gray')
plt.show()
```

**Output:**

    First X in the training data:

![png](/assets/images/output_1_1.png)

<br/>

*train_label* is an array with shape (60000). It contains the list of labels that correspond to each of the images in the *train_data* array. Having a labeled dataset means the algorithm doesn't have to come up with a list of classifications on its own. This is called supervised learning. 

```python
print("\nFirst label in the training data: " + str(train_label[0]))
```

**Output:**

    First label in the training data: 5
    
<br/>    
    
The *test_data* and *test_label* arrays will be used to test the trained model on a dataset outside of the data it used for learning. The testing dataset only has 10000 images as opposed to the 60000 images it was trained on. 


# Preprocessing the MNIST Dataset
The next step is to process the data to be used during training. First, reshape the data arrays so that there is a fourth dimension. This is the tensor shape the data must be in order to fit into the input layer of the model. This new dimension represents the number of color channels the images have. The "1" indicates greyscale. 
```python
train_data = train_data.reshape(60000, 28, 28, 1)
test_data = test_data.reshape(10000, 28, 28, 1)
print(train_data.shape, 'train samples')
print(test_data.shape, 'test samples')
```

**Output:**  

    (60000, 784) train samples
    (10000, 784) test samples

<br/>

Next the data must be converted from a uint8 datatype to float32.

```python
# check datatype
print("original datatype: " + str(train_data.dtype))
# convert x values to float32
train_data = train_data.astype('float32')
test_data = test_data.astype('float32')
train_label = train_label.astype('float32')
test_label = test_label.astype('float32')
print("new datatype: " + str(train_data.dtype))
```

**Output:**  

    original datatype: uint8
    new datatype: float32

<br/>

Next the pixels must be scaled from 0 to 1

```python
print("mean raw pixel value: " + str(np.mean(train_data[0])))

# scale pixel values from 0 to 1
X_train /= 255
X_test /= 255

print("mean scaled pixel value: " + str(np.mean(train_data[0])))
```

**Output:**  

    35.108418
    0.13768007
    
<br/>    

Next the label data must be converted to categortical data. In classification neural networks, the final output layer is an array of binary numbers that has the length equivalent to the number of possible classes being identified by the model. Only one of the numbers in the array can be a "1", indicating which class the input has been categorized into by the model. This dataset has 10 possible digits the model can identify. In the example below, the sixth binary number is flipped to "1" indicating that the label is the number five.

```python
# convert label data into categorical data
num_classes=10
train_label = keras.utils.to_categorical(train_label, num_classes)
test_label = keras.utils.to_categorical(test_label, num_classes)
print("\nFirst label in the training data is " + str(train_label[0]))
```

**Output:**    

    First label in the training data is [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
    
<br/>

# Building the model

To create the model, call the *Sequential()* method. This is a sequential order of keras layers that has data flowing from one layer to the next until it reaches the output layer. 

```python
model = Sequential()
```

This model primarily relies on the convoltional layer or the Conv2D layer. This layer applies a filter to the array of pixels in order to create an output image that is downsampled. These various filters produce images that highlight various features within the image, such as vertical or horizontal edges. Watch [this video](https://www.youtube.com/watch?v=C_zFhWdM4ic) to learn about how filters change the pixels of an image. The first parameter of the Conv2D layer dictates the number of filters applied to the input. The kernal size dictates the the convolutional window size. The activation parameter describes the mathematical function that the model will apply to the input of each neuron. The "relu" function is a non-linear function that returns the input if it is non-zero and returns zero if the input is negative.


```python
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=train_data[0].shape, name = 'conv2d_1))
```

The next type of layer used is the max pooling layer. Much of the information contained in the Conv2D layer is redundant, so the max pooling layer will apply a 2x2 filter across the output from the previous layer and find the maximum pixel value. More information about pooling can be found [here](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/).

```python
model.add(MaxPooling2D(pool_size=(2, 2), name='Pool_1'))
```

A drop out layer is a very important layer in regards to preventing overfitting of the data. It does this by learning a fraction of the weights in the network through each training iteration. More information about how drop out layers work can be found [here](https://towardsdatascience.com/simplified-math-behind-dropout-in-deep-learning-6d50f3f47275).

```python
model.add(Dropout(0.2, name='Dropout_1'))
```

Add another set of convolution, pooling, and dropout layers to make the neural network deeper and therefore more accurate.

```python
model.add(Conv2D(64, (3, 3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2), name='Pool_2'))

model.add(Dropout(0.2, name='Dropout_2'))
```

The flatten layer simply collapses the spatial dimensions into a single column in the array.

```python
model.add(Flatten(name='Flatten'), )
```

A dense layer is a regular, deeply-connected, neural network layer. 
The first parameter in the dense layer defines the output shape. The "softmax" function is commonly used in the final layer in classification neural networks. It returns a probability distribution of the 10 possible labels and the label with the highest probability is chosen.

```python
model.add(Dense(num_classes, activation='softmax', name="Dense_output"))
```

Get a summary of the constructed model with the function below.

```python
model.summary()
```

**Output:**  

    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       
    _________________________________________________________________
    Pool_1 (MaxPooling2D)        (None, 13, 13, 64)        0         
    _________________________________________________________________
    Dropout_1 (Dropout)          (None, 13, 13, 64)        0         
    _________________________________________________________________
    conv2d_2 (Conv2D)            (None, 11, 11, 64)        36928     
    _________________________________________________________________
    Pool_2 (MaxPooling2D)        (None, 5, 5, 64)          0         
    _________________________________________________________________
    Dropout_2 (Dropout)          (None, 5, 5, 64)          0         
    _________________________________________________________________
    Flatten (Flatten)            (None, 1600)              0         
    _________________________________________________________________
    Dense_output (Dense)         (None, 10)                16010     
    =================================================================
    Total params: 53,578
    Trainable params: 53,578
    Non-trainable params: 0
    _________________________________________________________________
    
<br/>

The summary shown above gives you every layer in the model with its associated output shape. The number of parameters in each layer are the weights that are learned during training.

Now we can compile the model and define which loss function and optimizer will be used during training. The loss function calculates the model error and the optimizer algorithm dictates how it will iteratively update the model's weights based on the given training data.

```python
# compile the model
model.compile(loss='categorical_crossentropy',
              optimizer="adam",
              metrics=['accuracy'])

# print the attributes of the model to ensure they're correct
print("Loss function: " + model.loss)
print("Optimizer: " + str(model.optimizer))
print("Metrics: " + str(model.metrics))
```

**Output:**  

    Loss function: categorical_crossentropy
    Optimizer: <keras.optimizers.Adam object at 0x000001DA0C2C8B38
    Metrics: [<keras.metrics.MeanMetricWrapper object at 0x0000022CCE63AC18>]
 
<br/>

# Train the Model

We can finally start training the model! The batch size dictates how many samples from the training dataset to work through before updating the model parameters. It can range anywhere from 1 to the size of the training dataset (in this case 48000). Using batch sizes will estimate what the gradient of the full dataset will be by taking samples from the training dataset. Smaller batchsizes may generally be less accurate however it may also help overfitting by avoiding local minima during the gradient descent. The number of epochs is how many times the entire training dataset is worked through. The early stopping monitor with a patience of 3 means if the accuracy of the model does not increase after 3 epochs, the training will stop.

```python
# choose the batch size
batch_size = 128

# initialize early stopping monitor
early_stopping_monitor = EarlyStopping(patience=3)

# fit the model 
fit1 = model.fit(train_data, train_label,
                    batch_size=batch_size,
                    epochs=12,`
                    callbacks = [early_stopping_monitor],
                    verbose=1,
                    validation_data = (test_data,test_label))
```

The training output is shown below. You can see how the loss is reduced and accuracy is increased over the course of many epochs until the rate of change peters out.

**Output:**  
    
    Train on 48000 samples, validate on 12000 samples
    Epoch 1/12
    48000/48000 [==============================] - 59s 1ms/step - loss: 0.3228 - accuracy: 0.9025 - val_loss: 0.0953 - val_accuracy: 0.9730
    Epoch 2/12
    48000/48000 [==============================] - 60s 1ms/step - loss: 0.0940 - accuracy: 0.9712 - val_loss: 0.0624 - val_accuracy: 0.9813
    Epoch 3/12
    48000/48000 [==============================] - 72s 1ms/step - loss: 0.0706 - accuracy: 0.9780 - val_loss: 0.0565 - val_accuracy: 0.9835
    Epoch 4/12
    48000/48000 [==============================] - 69s 1ms/step - loss: 0.0591 - accuracy: 0.9815 - val_loss: 0.0491 - val_accuracy: 0.9864
    Epoch 5/12
    48000/48000 [==============================] - 54s 1ms/step - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.0420 - val_accuracy: 0.9882
    Epoch 6/12
    48000/48000 [==============================] - 62s 1ms/step - loss: 0.0444 - accuracy: 0.9859 - val_loss: 0.0404 - val_accuracy: 0.9889
    Epoch 7/12
    48000/48000 [==============================] - 68s 1ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 0.0421 - val_accuracy: 0.9871
    Epoch 8/12
    48000/48000 [==============================] - 62s 1ms/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.0377 - val_accuracy: 0.9894
    Epoch 9/12
    48000/48000 [==============================] - 75s 2ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.0331 - val_accuracy: 0.9908
    Epoch 10/12
    48000/48000 [==============================] - 61s 1ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0357 - val_accuracy: 0.9904
    Epoch 11/12
    48000/48000 [==============================] - 69s 1ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0373 - val_accuracy: 0.9895
    Epoch 12/12
    48000/48000 [==============================] - 62s 1ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0338 - val_accuracy: 0.9902

<br/>

# Evaluate the Model

We can evaluate the loss and accuracy of the completed model using the following function. Notice that our model has over a 99% accuracy on the test dataset! However it is not too surprising since the test dataset was sourced from the same training datset.

```python
# evaluate the model
score = model.evaluate(test_data, test_label, verbose=0)

# print model loss and accuracy
print('Test loss:', score[0])
print('Test accuracy:', score[1])
```

**Output:**  

    Test loss: 0.027934746379594436
    Test accuracy: 0.9922000169754028
<br/>

What if we wanted to test this model on a digit from outside the MNIST dataset entirely? I did this by taking a picture of my own handwritten number five digit and processed it
similarly to how the MNIST dataset is processed. I opened the picture I took and converted it to grayscale first.

```python
img = Image.open('five.jpg').convert("L")
plt.imshow(img, cmap='gray')
plt.show()
```

**Output:**  

![png](/assets/images/five.jpg)

<br/>

In order to properly utilize the model I must manipulate the data of the image to the input shape of the model we've trained. This means I must first resize it to a 28 by 28 image. Then I must reshape it to a single array of pixels that are represented by the float32 datatype and scaled accordingly. Using the model.predict_classes function we can see if the model can accurately discern which digit I drew.

```python
img = np.resize(img, (28,28,1))
img_ar = np.array(img)
img_re = img_ar.reshape(1,784)
img_fl = img_re.astype("float32")
img_sc = img_fl/255
y_pred = model.predict_classes(img_sc)
print(y_pred)
```

**Output:**  

    [5]
    
The model correctly saw the image as the five digit! This furthur validates the effectiveness of the model and shows how powerful a properly trained neural network can be.
